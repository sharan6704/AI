
import numpy as np
import heapq

class PuzzleState:
    def __init__(self, board, g, goal):
        self.board = board
        self.g = g  # Cost to reach this state
        self.goal = goal
        self.h = self.count_mismatches()  # Heuristic based on number of mismatches
        self.f = self.g + self.h

    def count_mismatches(self):
        mismatches = 0
        self.mismatched_tiles = []  # Track mismatched tiles
        for i in range(3):
            for j in range(3):
                value = self.board[i][j]
                if value != 0 and value != self.goal[i, j]:  # Count mismatches (ignore blank tile)
                    mismatches += 1
                    self.mismatched_tiles.append(value)  # Store mismatched tile values
        return mismatches

    def is_goal(self):
        return np.array_equal(self.board, self.goal)

    def __str__(self):
        return str(self.board)

    def __lt__(self, other):
        return self.f < other.f  # For priority queue

def get_possible_moves(state):
    zero_position = np.argwhere(state.board == 0)[0]
    x, y = zero_position
    moves = []

    directions = [(1, 0), (-1, 0), (0, 1), (0, -1)]
    
    for dx, dy in directions:
        new_x, new_y = x + dx, y + dy
        if 0 <= new_x < 3 and 0 <= new_y < 3:  # Boundary check
            new_board = state.board.copy()
            new_board[x, y], new_board[new_x, new_y] = new_board[new_x, new_y], new_board[x, y]
            moves.append(PuzzleState(new_board, state.g + 1, state.goal))  # Increment g(n) correctly

    return moves

def display_board(board):
    print("Current Board:")
    print(board)
    print("-" * 30)  # Separator

def display_mismatches(state):
    mismatched_tiles = state.mismatched_tiles
    if mismatched_tiles:
        print(f"Mismatched tiles: {mismatched_tiles}")
    else:
        print("All tiles are in the correct position.")
    print("-" * 30)  # Separator

def a_star_search(initial_board, goal_board):
    initial_state = PuzzleState(initial_board, 0, goal_board)  # g(n) starts at 0
    if initial_state.is_goal():
        print("Initial state is the goal state.")
        return initial_state

    open_list = []
    heapq.heappush(open_list, initial_state)
    closed_set = set()
    states_explored = 0  # Counter for states explored

    while open_list:
        current_state = heapq.heappop(open_list)

        if current_state.is_goal():
            print(f"Goal state found:\n{current_state}")
            print(f"Total states explored: {states_explored}")
            return current_state

        closed_set.add(str(current_state))
        states_explored += 1  # Increment states explored

        # Display the current board state and mismatched tiles
        display_board(current_state.board)
        display_mismatches(current_state)

        for neighbor in get_possible_moves(current_state):
            if str(neighbor) not in closed_set:  # Avoid already visited states
                print(f"Exploring: {neighbor} | g(n): {neighbor.g} | h(n): {neighbor.h} | f(n): {neighbor.f}")
                heapq.heappush(open_list, neighbor)

    print("No solution found.")
    print(f"Total states explored: {states_explored}")
    return None

# Example usage
initial_board = np.array([[2, 8, 3],
                          [1, 6, 4],
                          [7, 0, 5]])
goal_board = np.array([[1, 2, 3],
                       [8, 0, 4],
                       [7, 6, 5]])

a_star_search(initial_board, goal_board)

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

output:
Current Board:
[[2 8 3]
 [1 6 4]
 [7 0 5]]
------------------------------
Mismatched tiles: [2, 8, 1, 6]
------------------------------
Exploring: [[2 8 3]
 [1 0 4]
 [7 6 5]] | g(n): 1 | h(n): 3 | f(n): 4
Exploring: [[2 8 3]
 [1 6 4]
 [7 5 0]] | g(n): 1 | h(n): 5 | f(n): 6
Exploring: [[2 8 3]
 [1 6 4]
 [0 7 5]] | g(n): 1 | h(n): 5 | f(n): 6
Current Board:
[[2 8 3]
 [1 0 4]
 [7 6 5]]
------------------------------
Mismatched tiles: [2, 8, 1]
------------------------------
Exploring: [[2 0 3]
 [1 8 4]
 [7 6 5]] | g(n): 2 | h(n): 3 | f(n): 5
Exploring: [[2 8 3]
 [1 4 0]
 [7 6 5]] | g(n): 2 | h(n): 4 | f(n): 6
Exploring: [[2 8 3]
 [0 1 4]
 [7 6 5]] | g(n): 2 | h(n): 3 | f(n): 5
Current Board:
[[2 0 3]
 [1 8 4]
 [7 6 5]]
------------------------------
Mismatched tiles: [2, 1, 8]
------------------------------
Exploring: [[2 3 0]
 [1 8 4]
 [7 6 5]] | g(n): 3 | h(n): 4 | f(n): 7
Exploring: [[0 2 3]
 [1 8 4]
 [7 6 5]] | g(n): 3 | h(n): 2 | f(n): 5
Current Board:
[[2 8 3]
 [0 1 4]
 [7 6 5]]
------------------------------
Mismatched tiles: [2, 8, 1]
------------------------------
Exploring: [[2 8 3]
 [7 1 4]
 [0 6 5]] | g(n): 3 | h(n): 4 | f(n): 7
Exploring: [[0 8 3]
 [2 1 4]
 [7 6 5]] | g(n): 3 | h(n): 3 | f(n): 6
Current Board:
[[0 2 3]
 [1 8 4]
 [7 6 5]]
------------------------------
Mismatched tiles: [1, 8]
------------------------------
Exploring: [[1 2 3]
 [0 8 4]
 [7 6 5]] | g(n): 4 | h(n): 1 | f(n): 5
Current Board:
[[1 2 3]
 [0 8 4]
 [7 6 5]]
------------------------------
Mismatched tiles: [8]
------------------------------
Exploring: [[1 2 3]
 [7 8 4]
 [0 6 5]] | g(n): 5 | h(n): 2 | f(n): 7
Exploring: [[1 2 3]
 [8 0 4]
 [7 6 5]] | g(n): 5 | h(n): 0 | f(n): 5
Goal state found:
[[1 2 3]
 [8 0 4]
 [7 6 5]]
Total states explored: 6

--------------------------